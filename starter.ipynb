{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cb39507e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import MutableMapping\n",
    "from collections import UserDict\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.utils.data as data_utils\n",
    "from tqdm.auto import tqdm\n",
    "\n",
    "from laplace import Laplace\n",
    "\n",
    "import logging\n",
    "import warnings\n",
    "\n",
    "logging.basicConfig(level=\"ERROR\")\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "from transformers import ( # noqa: E402\n",
    "    GPT2Config,\n",
    "    GPT2ForSequenceClassification,\n",
    "    GPT2Tokenizer,\n",
    "    DataCollatorWithPadding,\n",
    "    PreTrainedTokenizer,\n",
    ")\n",
    "from peft import LoraConfig, get_peft_model # noqa: E402\n",
    "from datasets import Dataset, load_dataset# noqa: E402\n",
    "# make deterministic\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89756785",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of labels: 28\n"
     ]
    }
   ],
   "source": [
    "model_name = \"tingtone/go_emo_gpt\"\n",
    "tokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
    "tokenizer.pad_token_id = tokenizer.eos_token_id\n",
    "\n",
    "# data = [\n",
    "#     {\"text\": \"Today is hot, but I will manage!!!!\", \"label\": 1},\n",
    "#     {\"text\": \"Tomorrow is cold\", \"label\": 0},\n",
    "#     {\"text\": \"Carpe diem\", \"label\": 1},\n",
    "#     {\"text\": \"Tempus fugit\", \"label\": 1},\n",
    "# ]\n",
    "dataset = load_dataset(\"go_emotions\")\n",
    "test_dataset = dataset[\"test\"]\n",
    "train_dataset = dataset[\"train\"]\n",
    "val_dataset = dataset[\"validation\"]\n",
    "num_labels = dataset[\"train\"].features[\"labels\"].feature.num_classes  # => 28\n",
    "print(f\"Number of labels: {num_labels}\")\n",
    "\n",
    "\n",
    "train_dataset = train_dataset.shuffle(seed=42).select(range(10))\n",
    "def preprocess(batch):\n",
    "    # 1) Tokenize to lists only\n",
    "    toks = tokenizer(\n",
    "        batch[\"text\"],\n",
    "        truncation=True,      # truncate long sequences\n",
    "        max_length=1024,      # but DON'T pad here\n",
    "        padding=False\n",
    "    )\n",
    "    # 2) Build multi-hot labels as Python lists\n",
    "    mh = np.zeros((len(batch[\"labels\"]), num_labels), dtype=np.float32)\n",
    "    for i, labs in enumerate(batch[\"labels\"]):\n",
    "        mh[i, labs] = 1\n",
    "    toks[\"label\"] = mh.tolist()\n",
    "    return toks\n",
    "\n",
    "# Apply without setting torch format\n",
    "train_dataset = train_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
    "val_dataset   = val_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
    "test_dataset  = test_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "train_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "val_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "test_dataset.set_format(type=\"torch\", columns=[\"input_ids\", \"attention_mask\", \"label\"])\n",
    "\n",
    "collator = DataCollatorWithPadding(tokenizer)\n",
    "\n",
    "\n",
    "train_dataloader = data_utils.DataLoader(\n",
    "    train_dataset, batch_size=100, collate_fn=collator\n",
    ")\n",
    "\n",
    "val_dataloader = data_utils.DataLoader(\n",
    "    val_dataset, batch_size=100, collate_fn=collator\n",
    ")\n",
    "test_dataloader = data_utils.DataLoader(\n",
    "    test_dataset, batch_size=100, collate_fn=collator\n",
    ")\n",
    "\n",
    "# data = next(iter(train_dataloader))\n",
    "# print(\n",
    "#     f\"Huggingface data defaults to UserDict, which is a MutableMapping? {isinstance(data, UserDict)}\"\n",
    "# )\n",
    "# for k, v in data.items():\n",
    "#     print(k, v.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a348f5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyGPT2(nn.Module):\n",
    "    \"\"\"\n",
    "    Huggingface LLM wrapper.\n",
    "\n",
    "    Args:\n",
    "        tokenizer: The tokenizer used for preprocessing the text data. Needed\n",
    "            since the model needs to know the padding token id.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, tokenizer: PreTrainedTokenizer) -> None:\n",
    "        super().__init__()\n",
    "        config = GPT2Config.from_pretrained(model_name)\n",
    "        config.pad_token_id = tokenizer.pad_token_id\n",
    "        config.num_labels = num_labels\n",
    "        self.hf_model = GPT2ForSequenceClassification.from_pretrained(\n",
    "            model_name, config=config\n",
    "        )\n",
    "\n",
    "    def forward(self, data: MutableMapping) -> torch.Tensor:\n",
    "        \"\"\"\n",
    "        Custom forward function. Handles things like moving the\n",
    "        input tensor to the correct device inside.\n",
    "\n",
    "        Args:\n",
    "            data: A dict-like data structure with `input_ids` inside.\n",
    "                This is the default data structure assumed by Huggingface\n",
    "                dataloaders.\n",
    "\n",
    "        Returns:\n",
    "            logits: An `(batch_size, n_classes)`-sized tensor of logits.\n",
    "        \"\"\"\n",
    "        device = next(self.parameters()).device\n",
    "        input_ids = data[\"input_ids\"].to(device)\n",
    "        attn_mask = data[\"attention_mask\"].to(device)\n",
    "        output_dict = self.hf_model(input_ids=input_ids, attention_mask=attn_mask)\n",
    "        return output_dict.logits\n",
    "\n",
    "model = MyGPT2(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b54752ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyGPT2(tokenizer)\n",
    "model.eval()\n",
    "\n",
    "la = Laplace(\n",
    "    model,\n",
    "    likelihood=\"classification\",\n",
    "    subset_of_weights=\"last_layer\",\n",
    "    hessian_structure=\"diag\",\n",
    "    # This must reflect faithfully the reduction technique used in the model\n",
    "    # Otherwise, correctness is not guaranteed\n",
    "    feature_reduction=\"pick_last\",\n",
    ")\n",
    "la.fit(train_loader=train_dataloader)\n",
    "la.optimize_prior_precision()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7f049d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0fb8d94c07d5439f832b2abc62b8e1e7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Evaluating:   0%|          | 0/55 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "all_logits = []\n",
    "all_la_preds = []\n",
    "all_labels = []\n",
    "total_loss = 0.0\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"mps\"\n",
    "for batch in tqdm(test_dataloader, desc=\"Evaluating\"):\n",
    "    data = {k: v.to(device) for k, v in batch.items()}\n",
    "    # input_ids      = batch[\"input_ids\"].to(device)\n",
    "    # attention_mask = batch[\"attention_mask\"].to(device)\n",
    "    labels         = batch[\"labels\"].to(device)\n",
    "    labels = labels.float()\n",
    "    with torch.no_grad():\n",
    "        logits = model(data)\n",
    "        # loss   = loss_fn(logits, labels)\n",
    "    la_pred = la(batch)\n",
    "\n",
    "    # total_loss += loss.item()\n",
    "    all_logits.append(logits.cpu().numpy())\n",
    "    all_la_preds.append(la_pred.cpu().numpy())\n",
    "    all_labels.append(labels.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "beb1eaa7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5427, 28) (5427, 28)\n",
      "(5427, 28)\n",
      "(5427, 28)\n"
     ]
    }
   ],
   "source": [
    "# stack arrays\n",
    "all_logits = np.vstack(all_logits)\n",
    "all_labels = np.vstack(all_labels)\n",
    "all_la_preds = np.vstack(all_la_preds)\n",
    "probs      = torch.sigmoid(torch.tensor(all_logits)).numpy()\n",
    "preds      = (probs >= 0.5).astype(int)\n",
    "la_preds  = (all_la_preds >= 0.5).astype(int)\n",
    "print(all_labels.shape, all_logits.shape)\n",
    "print(probs.shape)\n",
    "print(la_preds.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "17190859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Base GPT‑2 classifier ===\n",
      "Element-wise Accuracy: 0.9703\n",
      "Subset (Exact) Acc    : 0.5043\n",
      "Hamming Loss          : 0.0297\n",
      "F1 (micro)            :  0.6024\n",
      "F1 (macro)            :  0.4722\n",
      "ROC AUC (micro)       :  0.9557\n",
      "ROC AUC (macro)       :  0.9219\n",
      "Log Loss              : 0.0921\n",
      "Brier Score           : 0.0239\n",
      "Global ECE            : 0.0138\n",
      "Global MCE            : 0.2876\n",
      "Per‑class ECE         : [0.03275771 0.0102767  0.01654598 0.02848275 0.02734285 0.01318049\n",
      " 0.01122281 0.02363256 0.00763362 0.0155058  0.02236475 0.01278246\n",
      " 0.00305376 0.01160106 0.00443426 0.00629778 0.00038578 0.01055669\n",
      " 0.01219592 0.00305186 0.01285845 0.00185309 0.01476529 0.00080934\n",
      " 0.00546548 0.01274358 0.01265493 0.10553359]\n",
      "\n",
      "=== Last‑layer Laplace ===\n",
      "Element-wise Accuracy: 0.9583\n",
      "Subset (Exact) Acc    : 0.0000\n",
      "Hamming Loss          : 0.0417\n",
      "F1 (micro)            :  0.0000\n",
      "F1 (macro)            :  0.0000\n",
      "ROC AUC (micro)       :  0.9307\n",
      "ROC AUC (macro)       :  0.9188\n",
      "Log Loss              : 0.1427\n",
      "Brier Score           : 0.0365\n",
      "Global ECE            : 0.0474\n",
      "Global MCE            : 0.7008\n",
      "Per‑class ECE         : [0.08086695 0.05812621 0.04236483 0.04658495 0.0374322  0.02694865\n",
      " 0.04102496 0.0561679  0.02435931 0.03209502 0.04231885 0.04083208\n",
      " 0.03009482 0.02630788 0.03281795 0.07965472 0.0318903  0.04024939\n",
      " 0.04892257 0.03066773 0.03560615 0.03157174 0.02192063 0.03392192\n",
      " 0.03724778 0.04296213 0.03343279 0.26269731]\n"
     ]
    }
   ],
   "source": [
    "from metrics import (\n",
    "    elementwise_accuracy,\n",
    "    subset_accuracy,\n",
    "    hamming_loss,\n",
    "    f1_scores,\n",
    "    roc_auc_scores,\n",
    "    log_loss_multilabel,\n",
    "    brier_score_multilabel,\n",
    "    get_calibration,\n",
    ")\n",
    "\n",
    "# ——— Base GPT‑2 classifier metrics ———\n",
    "print(\"=== Base GPT‑2 classifier ===\")\n",
    "print(f\"Element-wise Accuracy: {elementwise_accuracy(all_labels, preds):.4f}\")\n",
    "print(f\"Subset (Exact) Acc    : {subset_accuracy(all_labels, preds):.4f}\")\n",
    "print(f\"Hamming Loss          : {hamming_loss(all_labels, preds):.4f}\")\n",
    "print(f\"F1 (micro)            : {f1_scores(all_labels, preds, average='micro'): .4f}\")\n",
    "print(f\"F1 (macro)            : {f1_scores(all_labels, preds, average='macro'): .4f}\")\n",
    "print(f\"ROC AUC (micro)       : {roc_auc_scores(all_labels, probs, average='micro'): .4f}\")\n",
    "print(f\"ROC AUC (macro)       : {roc_auc_scores(all_labels, probs, average='macro'): .4f}\")\n",
    "print(f\"Log Loss              : {log_loss_multilabel(all_labels, probs):.4f}\")\n",
    "print(f\"Brier Score           : {brier_score_multilabel(all_labels, probs):.4f}\")\n",
    "ece_cls, ece_glob, mce_glob = get_calibration(probs, all_labels)\n",
    "print(f\"Global ECE            : {ece_glob:.4f}\")\n",
    "print(f\"Global MCE            : {mce_glob:.4f}\")\n",
    "print(f\"Per‑class ECE         : {ece_cls}\")\n",
    "\n",
    "# ——— Laplace‑augmented model metrics ———\n",
    "print(\"\\n=== Last‑layer Laplace ===\")\n",
    "print(f\"Element-wise Accuracy: {elementwise_accuracy(all_labels, la_preds):.4f}\")\n",
    "print(f\"Subset (Exact) Acc    : {subset_accuracy(all_labels, la_preds):.4f}\")\n",
    "print(f\"Hamming Loss          : {hamming_loss(all_labels, la_preds):.4f}\")\n",
    "print(f\"F1 (micro)            : {f1_scores(all_labels, la_preds, average='micro'): .4f}\")\n",
    "print(f\"F1 (macro)            : {f1_scores(all_labels, la_preds, average='macro'): .4f}\")\n",
    "print(f\"ROC AUC (micro)       : {roc_auc_scores(all_labels, all_la_preds, average='micro'): .4f}\")\n",
    "print(f\"ROC AUC (macro)       : {roc_auc_scores(all_labels, all_la_preds, average='macro'): .4f}\")\n",
    "print(f\"Log Loss              : {log_loss_multilabel(all_labels, all_la_preds):.4f}\")\n",
    "print(f\"Brier Score           : {brier_score_multilabel(all_labels, all_la_preds):.4f}\")\n",
    "ece_cls_la, ece_glob_la, mce_glob_la = get_calibration(all_la_preds, all_labels)\n",
    "print(f\"Global ECE            : {ece_glob_la:.4f}\")\n",
    "print(f\"Global MCE            : {mce_glob_la:.4f}\")\n",
    "print(f\"Per‑class ECE         : {ece_cls_la}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BayesLLM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
