{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "224040f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/chintansawla/Desktop/nlp_project/clean_project/venv/lib/python3.11/site-packages/huggingface_hub/utils/_deprecation.py:131: FutureWarning: 'Repository' (from 'huggingface_hub.repository') is deprecated and will be removed from version '1.0'. Please prefer the http-based alternatives instead. Given its large adoption in legacy code, the complete removal is only planned on next major release.\n",
      "For more details, please read https://huggingface.co/docs/huggingface_hub/concepts/git_vs_http.\n",
      "  warnings.warn(warning_message, FutureWarning)\n",
      "Cloning https://huggingface.co/sawlachintan/gpt2-goemotions-ft into local empty directory.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Working in /Users/chintansawla/Desktop/nlp_project/clean_project\n",
      "Cloning into temp: /var/folders/46/sjpfqcxn5k3_qybfjf14v03m0000gn/T/tmpnt_5na_6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   0%|          | 24.7k/2.32G [00:00<?, ?B/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   0%|          | 2.61M/2.32G [00:01<15:40, 2.64MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   0%|          | 7.64M/2.32G [00:03<15:52, 2.60MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   0%|          | 10.3M/2.32G [00:04<15:27, 2.67MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   1%|          | 15.6M/2.32G [00:06<15:17, 2.69MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   1%|          | 18.3M/2.32G [00:07<15:07, 2.72MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   1%|          | 23.2M/2.32G [00:09<15:42, 2.61MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   1%|          | 25.7M/2.32G [00:10<15:56, 2.57MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   1%|          | 28.2M/2.32G [00:11<15:49, 2.59MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   1%|▏         | 33.5M/2.32G [00:13<15:29, 2.64MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   2%|▏         | 38.8M/2.32G [00:15<15:13, 2.68MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   2%|▏         | 43.8M/2.32G [00:17<15:32, 2.62MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   2%|▏         | 46.4M/2.32G [00:18<15:32, 2.62MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   2%|▏         | 51.3M/2.32G [00:20<15:51, 2.55MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   2%|▏         | 53.8M/2.32G [00:21<15:48, 2.56MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   2%|▏         | 56.1M/2.32G [00:22<16:11, 2.50MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   3%|▎         | 61.0M/2.32G [00:24<16:04, 2.51MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   3%|▎         | 65.9M/2.32G [00:26<15:56, 2.53MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   3%|▎         | 68.2M/2.32G [00:27<16:23, 2.45MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   3%|▎         | 70.7M/2.32G [00:28<16:06, 2.50MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   3%|▎         | 73.1M/2.32G [00:29<16:05, 2.50MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   3%|▎         | 75.6M/2.32G [00:30<16:03, 2.50MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   3%|▎         | 80.0M/2.32G [00:32<16:51, 2.38MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   3%|▎         | 82.3M/2.32G [00:33<17:03, 2.34MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   4%|▎         | 86.8M/2.32G [00:35<17:12, 2.32MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   4%|▍         | 91.3M/2.32G [00:37<17:09, 2.32MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   4%|▍         | 93.5M/2.32G [00:38<17:17, 2.30MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   4%|▍         | 95.7M/2.32G [00:39<17:22, 2.29MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   4%|▍         | 98.0M/2.32G [00:40<17:20, 2.29MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   4%|▍         | 100M/2.32G [00:41<17:02, 2.33MB/s] \n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   4%|▍         | 103M/2.32G [00:42<16:58, 2.34MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   4%|▍         | 105M/2.32G [00:43<17:18, 2.29MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   5%|▍         | 107M/2.32G [00:44<17:03, 2.32MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   5%|▍         | 109M/2.32G [00:46<17:28, 2.26MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   5%|▍         | 111M/2.32G [00:47<17:19, 2.28MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   5%|▍         | 116M/2.32G [00:49<17:01, 2.31MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   5%|▍         | 118M/2.32G [00:50<17:00, 2.32MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   5%|▌         | 120M/2.32G [00:51<17:00, 2.31MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   5%|▌         | 123M/2.32G [00:52<17:09, 2.29MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   5%|▌         | 125M/2.32G [00:53<16:54, 2.32MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   5%|▌         | 127M/2.32G [00:54<17:07, 2.29MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   6%|▌         | 132M/2.32G [00:56<16:46, 2.33MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   6%|▌         | 134M/2.32G [00:57<16:33, 2.36MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   6%|▌         | 139M/2.32G [00:59<16:54, 2.31MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   6%|▌         | 141M/2.32G [01:00<16:43, 2.33MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   6%|▌         | 143M/2.32G [01:01<16:50, 2.31MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   6%|▌         | 145M/2.32G [01:02<17:02, 2.28MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   6%|▌         | 147M/2.32G [01:03<17:19, 2.24MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   6%|▋         | 150M/2.32G [01:04<16:56, 2.29MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   7%|▋         | 154M/2.32G [01:06<16:34, 2.34MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   7%|▋         | 157M/2.32G [01:07<16:44, 2.31MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   7%|▋         | 159M/2.32G [01:08<16:40, 2.32MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   7%|▋         | 161M/2.32G [01:09<16:40, 2.32MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   7%|▋         | 165M/2.32G [01:11<16:54, 2.28MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   7%|▋         | 168M/2.32G [01:12<16:56, 2.27MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   7%|▋         | 172M/2.32G [01:14<16:46, 2.29MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   7%|▋         | 174M/2.32G [01:15<16:58, 2.26MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   8%|▊         | 179M/2.32G [01:17<16:27, 2.33MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   8%|▊         | 181M/2.32G [01:18<16:22, 2.34MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   8%|▊         | 183M/2.32G [01:19<16:42, 2.29MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   8%|▊         | 188M/2.32G [01:21<16:39, 2.29MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   8%|▊         | 192M/2.32G [01:23<16:46, 2.27MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   8%|▊         | 194M/2.32G [01:24<16:46, 2.27MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   8%|▊         | 199M/2.32G [01:26<16:30, 2.30MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   8%|▊         | 201M/2.32G [01:27<16:36, 2.28MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   9%|▊         | 203M/2.32G [01:29<16:31, 2.29MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   9%|▉         | 208M/2.32G [01:31<17:13, 2.20MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   9%|▉         | 210M/2.32G [01:32<16:50, 2.24MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   9%|▉         | 214M/2.32G [01:34<16:46, 2.25MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   9%|▉         | 217M/2.32G [01:35<16:20, 2.30MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   9%|▉         | 222M/2.32G [01:37<15:19, 2.45MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:   9%|▉         | 224M/2.32G [01:38<15:10, 2.47MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  10%|▉         | 227M/2.32G [01:39<15:01, 2.50MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  10%|▉         | 229M/2.32G [01:40<14:58, 2.50MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  10%|▉         | 232M/2.32G [01:41<14:53, 2.51MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  10%|▉         | 236M/2.32G [01:43<15:16, 2.44MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  10%|█         | 239M/2.32G [01:44<15:04, 2.47MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  10%|█         | 241M/2.32G [01:45<14:43, 2.53MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  10%|█         | 244M/2.32G [01:46<14:52, 2.50MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  10%|█         | 248M/2.32G [01:48<15:15, 2.43MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  11%|█         | 251M/2.32G [01:49<15:18, 2.42MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  11%|█         | 253M/2.32G [01:50<15:21, 2.41MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  11%|█         | 255M/2.32G [01:51<15:46, 2.34MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  11%|█         | 257M/2.32G [01:52<15:32, 2.38MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  11%|█         | 262M/2.32G [01:54<15:56, 2.31MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  11%|█         | 264M/2.32G [01:55<15:43, 2.34MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  11%|█         | 266M/2.32G [01:56<15:41, 2.34MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  11%|█▏        | 269M/2.32G [01:57<15:48, 2.32MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  12%|█▏        | 273M/2.32G [01:59<15:59, 2.29MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  12%|█▏        | 277M/2.32G [02:01<16:12, 2.26MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  12%|█▏        | 280M/2.32G [02:02<16:23, 2.23MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  12%|█▏        | 282M/2.32G [02:03<16:33, 2.20MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  12%|█▏        | 284M/2.32G [02:04<16:15, 2.24MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  12%|█▏        | 286M/2.32G [02:05<16:03, 2.27MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  12%|█▏        | 289M/2.32G [02:06<15:50, 2.30MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  12%|█▏        | 291M/2.32G [02:07<15:30, 2.34MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  12%|█▏        | 293M/2.32G [02:08<15:40, 2.32MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  12%|█▏        | 295M/2.32G [02:09<15:43, 2.31MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  13%|█▎        | 300M/2.32G [02:12<15:47, 2.29MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  13%|█▎        | 302M/2.32G [02:13<15:50, 2.28MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  13%|█▎        | 304M/2.32G [02:14<15:34, 2.32MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  13%|█▎        | 307M/2.32G [02:15<15:32, 2.32MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  13%|█▎        | 311M/2.32G [02:17<15:38, 2.30MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  13%|█▎        | 316M/2.32G [02:19<15:20, 2.34MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  13%|█▎        | 318M/2.32G [02:20<15:32, 2.31MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  14%|█▎        | 322M/2.32G [02:22<15:26, 2.32MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  14%|█▎        | 325M/2.32G [02:23<15:40, 2.28MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  14%|█▍        | 329M/2.32G [02:25<15:15, 2.34MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  14%|█▍        | 334M/2.32G [02:27<15:28, 2.30MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  14%|█▍        | 338M/2.32G [02:29<15:39, 2.27MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  14%|█▍        | 343M/2.32G [02:31<15:25, 2.30MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  15%|█▍        | 345M/2.32G [02:32<15:48, 2.24MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  15%|█▍        | 347M/2.32G [02:33<15:18, 2.31MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  15%|█▍        | 350M/2.32G [02:34<14:42, 2.40MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  15%|█▍        | 352M/2.32G [02:35<14:21, 2.46MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  15%|█▍        | 355M/2.32G [02:36<14:23, 2.45MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  15%|█▌        | 357M/2.32G [02:37<14:19, 2.46MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  15%|█▌        | 359M/2.32G [02:38<14:20, 2.45MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  15%|█▌        | 364M/2.32G [02:40<14:30, 2.42MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  15%|█▌        | 366M/2.32G [02:41<14:48, 2.36MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  16%|█▌        | 371M/2.32G [02:43<14:18, 2.44MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  16%|█▌        | 374M/2.32G [02:44<14:22, 2.43MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  16%|█▌        | 378M/2.32G [02:46<14:23, 2.42MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  16%|█▌        | 381M/2.32G [02:47<14:05, 2.47MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  16%|█▌        | 383M/2.32G [02:48<13:52, 2.50MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  16%|█▋        | 388M/2.32G [02:50<13:41, 2.53MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  17%|█▋        | 393M/2.32G [02:53<13:29, 2.56MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  17%|█▋        | 396M/2.32G [02:54<13:40, 2.52MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  17%|█▋        | 398M/2.32G [02:55<13:39, 2.52MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  17%|█▋        | 401M/2.32G [02:56<13:22, 2.57MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  17%|█▋        | 403M/2.32G [02:57<13:29, 2.55MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  17%|█▋        | 408M/2.32G [02:59<13:40, 2.51MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  17%|█▋        | 411M/2.32G [03:00<13:47, 2.48MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  17%|█▋        | 413M/2.32G [03:01<13:32, 2.53MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  18%|█▊        | 416M/2.32G [03:02<13:32, 2.52MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  18%|█▊        | 420M/2.32G [03:04<13:44, 2.48MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  18%|█▊        | 423M/2.32G [03:05<13:46, 2.47MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  18%|█▊        | 425M/2.32G [03:06<13:55, 2.44MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  18%|█▊        | 427M/2.32G [03:07<13:53, 2.45MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  18%|█▊        | 430M/2.32G [03:08<13:43, 2.47MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  18%|█▊        | 435M/2.32G [03:10<13:31, 2.50MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  19%|█▊        | 440M/2.32G [03:12<13:23, 2.52MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  19%|█▉        | 445M/2.32G [03:14<13:18, 2.53MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  19%|█▉        | 450M/2.32G [03:16<13:18, 2.52MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  19%|█▉        | 452M/2.32G [03:17<13:15, 2.53MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  19%|█▉        | 457M/2.32G [03:19<13:15, 2.52MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  19%|█▉        | 462M/2.32G [03:21<13:17, 2.51MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  20%|█▉        | 465M/2.32G [03:22<13:03, 2.55MB/s]\n",
      "\u001b[A\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  20%|█▉        | 470M/2.32G [03:24<13:04, 2.54MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  20%|█▉        | 472M/2.32G [03:25<13:08, 2.53MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  20%|██        | 474M/2.32G [03:26<13:08, 2.52MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  21%|██        | 487M/2.32G [03:28<07:10, 4.59MB/s]\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  21%|██        | 494M/2.32G [03:29<06:10, 5.31MB/s]\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  21%|██        | 501M/2.32G [03:30<05:30, 5.94MB/s]\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  21%|██▏       | 508M/2.32G [03:31<05:03, 6.43MB/s]\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  22%|██▏       | 514M/2.32G [03:32<04:58, 6.53MB/s]\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  22%|██▏       | 521M/2.32G [03:33<04:49, 6.69MB/s]\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  22%|██▏       | 528M/2.32G [03:34<04:43, 6.82MB/s]\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  23%|██▎       | 535M/2.32G [03:35<04:38, 6.90MB/s]\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  23%|██▎       | 542M/2.32G [03:36<04:37, 6.91MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  23%|██▎       | 548M/2.32G [03:37<04:36, 6.92MB/s]\n",
      "\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  23%|██▎       | 555M/2.32G [03:38<04:40, 6.78MB/s]\n",
      "\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  24%|██▎       | 561M/2.32G [03:39<04:35, 6.89MB/s]\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  24%|██▍       | 568M/2.32G [03:40<04:30, 6.99MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  25%|██▍       | 582M/2.32G [03:42<04:28, 7.00MB/s]\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  25%|██▌       | 595M/2.32G [03:44<04:29, 6.92MB/s]\n",
      "\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  25%|██▌       | 602M/2.32G [03:46<04:25, 6.98MB/s]\n",
      "\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  27%|██▋       | 632M/2.32G [03:50<04:01, 7.54MB/s]\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin:  30%|██▉       | 702M/2.32G [04:00<04:01, 7.25MB/s]\n",
      "\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin: 100%|█████████▉| 2.31G/2.32G [08:15<00:00, 6.89MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Download file ood-epochs-10-ense-5/pytorch_model.bin: 100%|██████████| 2.32G/2.32G [08:23<00:00, 4.94MB/s]\n",
      "Download file no-ood-epochs-10-ense-1/pytorch_model.bin: 100%|██████████| 474M/474M [08:23<00:00, 988kB/s] \n",
      "\n",
      "\u001b[A\n",
      "Download file ood-10-epochs/pytorch_model.bin: 100%|██████████| 474M/474M [08:23<00:00, 988kB/s] \n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\n",
      "\n",
      "Clean file no-ood-epochs-10-ense-1/pytorch_model.bin: 100%|██████████| 474M/474M [04:54<00:00, 1.64MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "Clean file ood-10-epochs/pytorch_model.bin: 100%|██████████| 474M/474M [04:46<00:00, 1.69MB/s]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[A\u001b[A\u001b[A\u001b[A\n",
      "\n",
      "\n",
      "\n",
      "Clean file ood-epochs-10-ense-5/pytorch_model.bin: 100%|██████████| 2.32G/2.32G [00:05<00:00, 474MB/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying /var/folders/46/sjpfqcxn5k3_qybfjf14v03m0000gn/T/tmpnt_5na_6/no-ood-epochs-10-ense-1 → /Users/chintansawla/Desktop/nlp_project/clean_project/no-ood-epochs-10-ense-1\n",
      "Cleaning up temp dir\n",
      "Done! Only keeping: ['.DS_Store', 'repo.ipynb', 'data_explore.ipynb', 'thresholds.csv', 'test.py', '.gitattributes', 'test_huggingface.ipynb', 'log', 'ood-10-epochs', 'venv', 'main.py', 'no-ood-epochs-10-ense-1']\n"
     ]
    }
   ],
   "source": [
    "from huggingface_hub import Repository\n",
    "import tempfile, shutil, os\n",
    "\n",
    "# ← change this to whatever folder you actually want to keep\n",
    "PREFERRED = \"no-ood-epochs-10-ense-1\"\n",
    "\n",
    "# 0) sanity check\n",
    "cwd = os.getcwd()\n",
    "print(\"Working in\", cwd)\n",
    "\n",
    "# 1) remove any existing model dirs (heuristic: contains *.lock files) except the one you want\n",
    "for name in os.listdir(cwd):\n",
    "    path = os.path.join(cwd, name)\n",
    "    if os.path.isdir(path):\n",
    "        # look for any files ending in .lock (metadata from hf download)\n",
    "        if any(f.endswith(\".lock\") for f in os.listdir(path)):\n",
    "            if name != PREFERRED:\n",
    "                print(f\"→ removing old folder {name}\")\n",
    "                shutil.rmtree(path)\n",
    "\n",
    "# 2) make a temp dir to clone the full HF repo\n",
    "tmp_dir = tempfile.mkdtemp()\n",
    "print(\"Cloning into temp:\", tmp_dir)\n",
    "repo = Repository(\n",
    "    local_dir=tmp_dir,\n",
    "    clone_from=\"sawlachintan/gpt2-goemotions-ft\",\n",
    "    use_auth_token=True\n",
    ")\n",
    "\n",
    "# 3) copy only your preferred subfolder back into ./PREFERRED\n",
    "src = os.path.join(tmp_dir, PREFERRED)\n",
    "dst = os.path.join(cwd, PREFERRED)\n",
    "\n",
    "# if it somehow already exists, nuke it\n",
    "if os.path.isdir(dst):\n",
    "    print(f\"→ removing stale copy at {dst}\")\n",
    "    shutil.rmtree(dst)\n",
    "\n",
    "print(f\"Copying {src} → {dst}\")\n",
    "shutil.copytree(src, dst)\n",
    "\n",
    "# 4) clean up the temp clone\n",
    "print(\"Cleaning up temp dir\")\n",
    "shutil.rmtree(tmp_dir)\n",
    "\n",
    "print(\"Done! Only keeping:\", os.listdir(cwd))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2f28aa97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at ./no-ood-epochs-10-ense-1 and are newly initialized: ['score.weight', 'transformer.h.0.attn.c_attn.bias', 'transformer.h.0.attn.c_attn.weight', 'transformer.h.0.attn.c_proj.bias', 'transformer.h.0.attn.c_proj.weight', 'transformer.h.0.ln_1.bias', 'transformer.h.0.ln_1.weight', 'transformer.h.0.ln_2.bias', 'transformer.h.0.ln_2.weight', 'transformer.h.0.mlp.c_fc.bias', 'transformer.h.0.mlp.c_fc.weight', 'transformer.h.0.mlp.c_proj.bias', 'transformer.h.0.mlp.c_proj.weight', 'transformer.h.1.attn.c_attn.bias', 'transformer.h.1.attn.c_attn.weight', 'transformer.h.1.attn.c_proj.bias', 'transformer.h.1.attn.c_proj.weight', 'transformer.h.1.ln_1.bias', 'transformer.h.1.ln_1.weight', 'transformer.h.1.ln_2.bias', 'transformer.h.1.ln_2.weight', 'transformer.h.1.mlp.c_fc.bias', 'transformer.h.1.mlp.c_fc.weight', 'transformer.h.1.mlp.c_proj.bias', 'transformer.h.1.mlp.c_proj.weight', 'transformer.h.10.attn.c_attn.bias', 'transformer.h.10.attn.c_attn.weight', 'transformer.h.10.attn.c_proj.bias', 'transformer.h.10.attn.c_proj.weight', 'transformer.h.10.ln_1.bias', 'transformer.h.10.ln_1.weight', 'transformer.h.10.ln_2.bias', 'transformer.h.10.ln_2.weight', 'transformer.h.10.mlp.c_fc.bias', 'transformer.h.10.mlp.c_fc.weight', 'transformer.h.10.mlp.c_proj.bias', 'transformer.h.10.mlp.c_proj.weight', 'transformer.h.11.attn.c_attn.bias', 'transformer.h.11.attn.c_attn.weight', 'transformer.h.11.attn.c_proj.bias', 'transformer.h.11.attn.c_proj.weight', 'transformer.h.11.ln_1.bias', 'transformer.h.11.ln_1.weight', 'transformer.h.11.ln_2.bias', 'transformer.h.11.ln_2.weight', 'transformer.h.11.mlp.c_fc.bias', 'transformer.h.11.mlp.c_fc.weight', 'transformer.h.11.mlp.c_proj.bias', 'transformer.h.11.mlp.c_proj.weight', 'transformer.h.2.attn.c_attn.bias', 'transformer.h.2.attn.c_attn.weight', 'transformer.h.2.attn.c_proj.bias', 'transformer.h.2.attn.c_proj.weight', 'transformer.h.2.ln_1.bias', 'transformer.h.2.ln_1.weight', 'transformer.h.2.ln_2.bias', 'transformer.h.2.ln_2.weight', 'transformer.h.2.mlp.c_fc.bias', 'transformer.h.2.mlp.c_fc.weight', 'transformer.h.2.mlp.c_proj.bias', 'transformer.h.2.mlp.c_proj.weight', 'transformer.h.3.attn.c_attn.bias', 'transformer.h.3.attn.c_attn.weight', 'transformer.h.3.attn.c_proj.bias', 'transformer.h.3.attn.c_proj.weight', 'transformer.h.3.ln_1.bias', 'transformer.h.3.ln_1.weight', 'transformer.h.3.ln_2.bias', 'transformer.h.3.ln_2.weight', 'transformer.h.3.mlp.c_fc.bias', 'transformer.h.3.mlp.c_fc.weight', 'transformer.h.3.mlp.c_proj.bias', 'transformer.h.3.mlp.c_proj.weight', 'transformer.h.4.attn.c_attn.bias', 'transformer.h.4.attn.c_attn.weight', 'transformer.h.4.attn.c_proj.bias', 'transformer.h.4.attn.c_proj.weight', 'transformer.h.4.ln_1.bias', 'transformer.h.4.ln_1.weight', 'transformer.h.4.ln_2.bias', 'transformer.h.4.ln_2.weight', 'transformer.h.4.mlp.c_fc.bias', 'transformer.h.4.mlp.c_fc.weight', 'transformer.h.4.mlp.c_proj.bias', 'transformer.h.4.mlp.c_proj.weight', 'transformer.h.5.attn.c_attn.bias', 'transformer.h.5.attn.c_attn.weight', 'transformer.h.5.attn.c_proj.bias', 'transformer.h.5.attn.c_proj.weight', 'transformer.h.5.ln_1.bias', 'transformer.h.5.ln_1.weight', 'transformer.h.5.ln_2.bias', 'transformer.h.5.ln_2.weight', 'transformer.h.5.mlp.c_fc.bias', 'transformer.h.5.mlp.c_fc.weight', 'transformer.h.5.mlp.c_proj.bias', 'transformer.h.5.mlp.c_proj.weight', 'transformer.h.6.attn.c_attn.bias', 'transformer.h.6.attn.c_attn.weight', 'transformer.h.6.attn.c_proj.bias', 'transformer.h.6.attn.c_proj.weight', 'transformer.h.6.ln_1.bias', 'transformer.h.6.ln_1.weight', 'transformer.h.6.ln_2.bias', 'transformer.h.6.ln_2.weight', 'transformer.h.6.mlp.c_fc.bias', 'transformer.h.6.mlp.c_fc.weight', 'transformer.h.6.mlp.c_proj.bias', 'transformer.h.6.mlp.c_proj.weight', 'transformer.h.7.attn.c_attn.bias', 'transformer.h.7.attn.c_attn.weight', 'transformer.h.7.attn.c_proj.bias', 'transformer.h.7.attn.c_proj.weight', 'transformer.h.7.ln_1.bias', 'transformer.h.7.ln_1.weight', 'transformer.h.7.ln_2.bias', 'transformer.h.7.ln_2.weight', 'transformer.h.7.mlp.c_fc.bias', 'transformer.h.7.mlp.c_fc.weight', 'transformer.h.7.mlp.c_proj.bias', 'transformer.h.7.mlp.c_proj.weight', 'transformer.h.8.attn.c_attn.bias', 'transformer.h.8.attn.c_attn.weight', 'transformer.h.8.attn.c_proj.bias', 'transformer.h.8.attn.c_proj.weight', 'transformer.h.8.ln_1.bias', 'transformer.h.8.ln_1.weight', 'transformer.h.8.ln_2.bias', 'transformer.h.8.ln_2.weight', 'transformer.h.8.mlp.c_fc.bias', 'transformer.h.8.mlp.c_fc.weight', 'transformer.h.8.mlp.c_proj.bias', 'transformer.h.8.mlp.c_proj.weight', 'transformer.h.9.attn.c_attn.bias', 'transformer.h.9.attn.c_attn.weight', 'transformer.h.9.attn.c_proj.bias', 'transformer.h.9.attn.c_proj.weight', 'transformer.h.9.ln_1.bias', 'transformer.h.9.ln_1.weight', 'transformer.h.9.ln_2.bias', 'transformer.h.9.ln_2.weight', 'transformer.h.9.mlp.c_fc.bias', 'transformer.h.9.mlp.c_fc.weight', 'transformer.h.9.mlp.c_proj.bias', 'transformer.h.9.mlp.c_proj.weight', 'transformer.ln_f.bias', 'transformer.ln_f.weight', 'transformer.wpe.weight', 'transformer.wte.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer, AutoConfig, AutoModelForSequenceClassification\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"./no-ood-epochs-10-ense-1\")\n",
    "config    = AutoConfig.from_pretrained(\n",
    "    \"gpt2\",\n",
    "    num_labels=28,\n",
    "    finetuning_task=\"multi_label_classification\",\n",
    "    pad_token_id=tokenizer.eos_token_id\n",
    ")\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\n",
    "    \"./no-ood-epochs-10-ense-1\",\n",
    "    config=config\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c1ede10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores: tensor([[0.5018, 0.5410, 0.4824, 0.3989, 0.5654, 0.2874, 0.6191, 0.4568, 0.8238,\n",
      "         0.6015, 0.4471, 0.4068, 0.4024, 0.5305, 0.4335, 0.5351, 0.2971, 0.3326,\n",
      "         0.7804, 0.6055, 0.6450, 0.3474, 0.7648, 0.6362, 0.6060, 0.6761, 0.3860,\n",
      "         0.4552],\n",
      "        [0.5344, 0.5606, 0.4227, 0.3549, 0.7709, 0.5586, 0.5748, 0.2480, 0.7037,\n",
      "         0.6027, 0.4832, 0.4159, 0.3430, 0.3890, 0.5046, 0.6251, 0.4929, 0.4419,\n",
      "         0.4972, 0.4933, 0.6439, 0.4950, 0.6389, 0.6756, 0.6051, 0.7122, 0.5622,\n",
      "         0.4897]])\n",
      "Binary preds: tensor([[1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1,\n",
      "         1, 1, 0, 0],\n",
      "        [1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1,\n",
      "         1, 1, 1, 0]])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "texts = [\"I love sunny days but hate the rain.\", \"I'm feeling curious and excited!\"]\n",
    "\n",
    "# 2. Tokenize + batch into tensors\n",
    "#    return_tensors=\"pt\" gives you PyTorch tensors,\n",
    "#    padding=True/truncation=True makes them all the same length\n",
    "inputs = tokenizer(\n",
    "    texts,\n",
    "    return_tensors=\"pt\",\n",
    "    padding=True,\n",
    "    truncation=True,\n",
    ")\n",
    "\n",
    "# 3. Move to GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "\n",
    "# 4. Forward pass (no gradient needed for inference)\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(**inputs)\n",
    "    logits = outputs.logits      # shape: (batch_size, num_labels)\n",
    "\n",
    "# 5. Convert logits → probabilities\n",
    "probs = torch.sigmoid(logits)    # multi-label, independent scores\n",
    "\n",
    "# 6. Threshold or inspect\n",
    "threshold = 0.5\n",
    "preds = (probs > threshold).long()  # 0/1 predictions per label\n",
    "\n",
    "print(\"Scores:\", probs)\n",
    "print(\"Binary preds:\", preds)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f19b565",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
